{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project\n",
        "\n",
        "## Predict whether a mammogram mass is benign or malignant\n",
        "\n",
        "We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n",
        "\n",
        "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
        "\n\n",
        "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
        "   2. Age: patient's age in years (integer)\n",
        "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
        "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
        "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
        "   6. Severity: benign=0 or malignant=1 (binominal)\n",
        "   \n",
        "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
        "\n",
        "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
        "\n",
        "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n",
        "\n",
        "## Your assignment\n",
        "\n",
        "Apply several different supervised machine learning techniques to this data set, and see which one yields the highest accuracy as measured with K-Fold cross validation (K=10). Apply:\n",
        "\n",
        "* Decision tree\n",
        "* Random forest\n",
        "* KNN\n",
        "* Naive Bayes\n",
        "* SVM\n",
        "* Logistic Regression\n",
        "* And, as a bonus challenge, a neural network using Keras.\n",
        "\n",
        "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
        "\n",
        "Remember some techniques such as SVM also require the input data to be normalized first.\n",
        "\n",
        "Many techniques also have \"hyperparameters\" that need to be tuned. Once you identify a promising approach, see if you can make it even better by tuning its hyperparameters.\n",
        "\n",
        "I was able to achieve over 80% accuracy - can you beat that?\n",
        "\n",
        "Below I've set up an outline of a notebook for this project, with some guidance and hints. If you're up for a real challenge, try doing this project from scratch in a new, clean notebook!\n"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's begin: prepare your data\n",
        "\nStart by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "masses_data = pd.read_csv('mammographic_masses.data.txt')\n",
        "masses_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "   5  67  3 5.1 3.1  1\n",
              "0  4  43  1   1   ?  1\n",
              "1  5  58  4   5   3  1\n",
              "2  4  28  1   1   3  0\n",
              "3  5  74  1   5   ?  1\n",
              "4  4  65  1   ?   3  0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5</th>\n",
              "      <th>67</th>\n",
              "      <th>3</th>\n",
              "      <th>5.1</th>\n",
              "      <th>3.1</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masses_data = pd.read_csv('mammographic_masses.data.txt', na_values=['?'], names = ['BI-RADS', 'age', 'shape', 'margin', 'density', 'severity'])\n",
        "masses_data.drop('BI-RADS', axis=1, inplace=True)\n",
        "masses_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "    age  shape  margin  density  severity\n",
              "0  67.0    3.0     5.0      3.0         1\n",
              "1  43.0    1.0     1.0      NaN         1\n",
              "2  58.0    4.0     5.0      3.0         1\n",
              "3  28.0    1.0     1.0      3.0         0\n",
              "4  74.0    1.0     5.0      NaN         1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>shape</th>\n",
              "      <th>margin</th>\n",
              "      <th>density</th>\n",
              "      <th>severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masses_data.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "              age       shape      margin     density    severity\n",
              "count  956.000000  930.000000  913.000000  885.000000  961.000000\n",
              "mean    55.487448    2.721505    2.796276    2.910734    0.463059\n",
              "std     14.480131    1.242792    1.566546    0.380444    0.498893\n",
              "min     18.000000    1.000000    1.000000    1.000000    0.000000\n",
              "25%     45.000000    2.000000    1.000000    3.000000    0.000000\n",
              "50%     57.000000    3.000000    3.000000    3.000000    0.000000\n",
              "75%     66.000000    4.000000    4.000000    3.000000    1.000000\n",
              "max     96.000000    4.000000    5.000000    4.000000    1.000000"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>shape</th>\n",
              "      <th>margin</th>\n",
              "      <th>density</th>\n",
              "      <th>severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>956.000000</td>\n",
              "      <td>930.000000</td>\n",
              "      <td>913.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>961.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.487448</td>\n",
              "      <td>2.721505</td>\n",
              "      <td>2.796276</td>\n",
              "      <td>2.910734</td>\n",
              "      <td>0.463059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.480131</td>\n",
              "      <td>1.242792</td>\n",
              "      <td>1.566546</td>\n",
              "      <td>0.380444</td>\n",
              "      <td>0.498893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>66.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masses_data[masses_data.isnull().any(axis=1)]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "      age  shape  margin  density  severity\n",
              "1    43.0    1.0     1.0      NaN         1\n",
              "4    74.0    1.0     5.0      NaN         1\n",
              "5    65.0    1.0     NaN      3.0         0\n",
              "6    70.0    NaN     NaN      3.0         0\n",
              "7    42.0    1.0     NaN      3.0         0\n",
              "9    60.0    NaN     5.0      1.0         1\n",
              "12   64.0    1.0     NaN      3.0         0\n",
              "19   40.0    1.0     NaN      NaN         0\n",
              "20   66.0    NaN     NaN      1.0         1\n",
              "22   43.0    1.0     NaN      NaN         0\n",
              "26   66.0    1.0     1.0      NaN         0\n",
              "27   63.0    3.0     NaN      3.0         0\n",
              "35   77.0    3.0     NaN      NaN         0\n",
              "38   48.0    4.0     5.0      NaN         1\n",
              "40   59.0    2.0     1.0      NaN         0\n",
              "43   61.0    2.0     1.0      NaN         0\n",
              "45   44.0    2.0     4.0      NaN         1\n",
              "47   23.0    1.0     1.0      NaN         0\n",
              "48   42.0    NaN     NaN      4.0         0\n",
              "52   23.0    1.0     1.0      NaN         0\n",
              "53   63.0    2.0     1.0      NaN         0\n",
              "54   53.0    NaN     5.0      3.0         1\n",
              "55   43.0    3.0     4.0      NaN         0\n",
              "57   51.0    2.0     4.0      NaN         0\n",
              "58   45.0    2.0     1.0      NaN         0\n",
              "59   59.0    2.0     NaN      NaN         1\n",
              "63   57.0    2.0     1.0      NaN         0\n",
              "65   25.0    2.0     1.0      NaN         0\n",
              "67   72.0    4.0     3.0      NaN         1\n",
              "74   70.0    NaN     4.0      NaN         1\n",
              "..    ...    ...     ...      ...       ...\n",
              "496  82.0    NaN     5.0      3.0         1\n",
              "501  59.0    4.0     4.0      NaN         1\n",
              "519  68.0    NaN     NaN      3.0         0\n",
              "520  62.0    4.0     NaN      3.0         1\n",
              "521  65.0    1.0     NaN      3.0         1\n",
              "531  55.0    NaN     NaN      3.0         0\n",
              "537  63.0    NaN     4.0      3.0         1\n",
              "541  49.0    2.0     NaN      3.0         0\n",
              "554  70.0    NaN     5.0      3.0         1\n",
              "561  59.0    NaN     4.0      3.0         0\n",
              "569  64.0    3.0     4.0      NaN         1\n",
              "574  60.0    3.0     NaN      NaN         0\n",
              "581  65.0    NaN     1.0      2.0         0\n",
              "614  46.0    NaN     5.0      NaN         1\n",
              "627  57.0    2.0     1.0      NaN         0\n",
              "660  58.0    NaN     4.0      3.0         1\n",
              "661  51.0    NaN     4.0      3.0         0\n",
              "662  50.0    NaN     NaN      3.0         1\n",
              "665  27.0    2.0     1.0      NaN         0\n",
              "677  57.0    4.0     4.0      NaN         1\n",
              "683   NaN    3.0     3.0      3.0         1\n",
              "691  72.0    3.0     NaN      3.0         0\n",
              "723  60.0    3.0     NaN      4.0         0\n",
              "745  76.0    3.0     NaN      3.0         0\n",
              "752  48.0    NaN     4.0      NaN         1\n",
              "778  60.0    NaN     4.0      3.0         0\n",
              "819  35.0    3.0     NaN      2.0         0\n",
              "824  40.0    NaN     3.0      4.0         1\n",
              "884   NaN    4.0     4.0      3.0         1\n",
              "923   NaN    4.0     3.0      3.0         1\n",
              "\n[130 rows x 5 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>shape</th>\n",
              "      <th>margin</th>\n",
              "      <th>density</th>\n",
              "      <th>severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>42.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>64.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>66.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>43.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>66.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>63.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>77.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>48.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>59.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>61.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>42.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>63.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>53.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>43.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>51.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>72.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>82.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>59.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>68.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>62.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>55.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>63.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>70.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>59.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>64.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>46.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>58.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>51.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>27.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>57.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>72.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>60.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>76.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>35.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>923</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows Ã— 5 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masses_data.dropna(inplace=True)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
      ],
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = masses_data[['age', 'shape',\n",
        "                             'margin', 'density']].values\n",
        "\n\n",
        "all_classes = masses_data['severity'].values\n",
        "feature_names = ['age', 'shape', 'margin', 'density']\n",
        "\nall_features"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": [
              "array([[67.,  3.,  5.,  3.],\n",
              "       [58.,  4.,  5.,  3.],\n",
              "       [28.,  1.,  1.,  3.],\n",
              "       ...,\n",
              "       [64.,  4.,  5.,  3.],\n",
              "       [66.,  4.,  5.,  3.],\n",
              "       [62.,  3.,  3.,  3.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "all_features_scaled = scaler.fit_transform(all_features)\n",
        "all_features_scaled"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": [
              "array([[ 0.76580356,  0.17445989,  1.39563127,  0.24031298],\n",
              "       [ 0.15166622,  0.97988304,  1.39563127,  0.24031298],\n",
              "       [-1.89545824, -1.43638642, -1.15892729,  0.24031298],\n",
              "       ...,\n",
              "       [ 0.56109111,  0.97988304,  1.39563127,  0.24031298],\n",
              "       [ 0.69756608,  0.97988304,  1.39563127,  0.24031298],\n",
              "       [ 0.42461615,  0.17445989,  0.11835199,  0.24031298]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees\n",
        "\nBefore moving to K-Fold cross validation and random forests, start by creating a single train/test split of our data. Set aside 75% for training, and 25% for testing."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(training_inputs,\n",
        " testing_inputs,\n",
        " training_classes,\n",
        " testing_classes) = train_test_split(all_features_scaled, all_classes, train_size=0.75, random_state=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/fede/Projects/MLNN/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a DecisionTreeClassifier and fit it to your training data."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf= DecisionTreeClassifier(random_state=1)\n",
        "# Train the classifier on the training set\n",
        "clf.fit(training_inputs, training_classes)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
              "            splitter='best')"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the resulting decision tree."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure the accuracy of the resulting decision tree model using your test data."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(testing_inputs, testing_classes)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": [
              "0.7067307692307693"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now instead of a single train/test split, use K-Fold cross validation to get a better measure of your model's accuracy (K=10). Hint: use model_selection.cross_val_score"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = DecisionTreeClassifier(random_state=1)\n",
        "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": [
              "0.7328586121489442"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try a RandomForestClassifier instead. Does it perform better?"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
        "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": [
              "0.7446895596322572"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM\n",
        "\nNext try using svm.SVC with a linear kernel. How does it compare to the decision tree?"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "C = 1.0\n",
        "svc = svm.SVC(kernel='linear', C=C)"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(svc, all_features_scaled, all_classes, cv=10)\n",
        "\ncv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": [
              "0.7955434980339476"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN\n",
        "How about K-Nearest-Neighbors? Hint: use neighbors.KNeighborsClassifier - it's a lot easier than implementing KNN from scratch like we did earlier in the course. Start with a K of 10. K is an example of a hyperparameter - a parameter on the model itself which may need to be tuned for best results on your particular data set."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
        "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "\ncv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": [
              "0.7857149853770482"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing K is tricky, so we can't discard KNN until we've tried different values of K. Write a for loop to run KNN with K values ranging from 1 to 50 and see if K makes a substantial difference. Make a note of the best performance you could get out of KNN."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_k = 0\n",
        "max_score = 0\n",
        "for n in range(1, 50):\n",
        "    clf = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
        "    cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "    mean = cv_scores.mean()\n",
        "    if mean > max_score:\n",
        "        max_k = n\n",
        "        max_score = mean\n",
        "print(max_k, max_score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 0.7918121965212768\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\nNow try naive_bayes.MultinomialNB. How does its accuracy stack up? Hint: you'll need to use MinMaxScaler to get the features in the range MultinomialNB requires."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "all_features_minmax = scaler.fit_transform(all_features)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "cv_scores = cross_val_score(clf, all_features_minmax, all_classes, cv=10)\n",
        "\ncv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": [
              "0.7823041294096245"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Revisiting SVM\n",
        "\nsvm.SVC may perform differently with different kernels. The choice of kernel is an example of a \"hyperparamter.\" Try the rbf, sigmoid, and poly kernels and see what the best-performing kernel is. Do we have a new winner?"
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = 1.0\n",
        "svc = svm.SVC(kernel='rbf', C=C)\n",
        "cv_scores = cross_val_score(svc, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": [
              "0.8002763667912067"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = 1.0\n",
        "svc = svm.SVC(kernel='sigmoid', C=C)\n",
        "cv_scores = cross_val_score(svc, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": [
              "0.7353847445531254"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = 1.0\n",
        "svc = svm.SVC(kernel='poly', C=C)\n",
        "cv_scores = cross_val_score(svc, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": [
              "0.7906084267383122"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\nWe've tried all these fancy techniques, but fundamentally this is just a binary classification problem. Try Logisitic Regression, which is a simple way to tackling this sort of thing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": [
              "0.8063735779354351"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks\n",
        "\nAs a bonus challenge, let's see if an artificial neural network can do even better. You can use Keras to set up a neural network with 1 binary output neuron and see how it performs. Don't be afraid to run a large number of epochs to train the model if necessary."
      ],
      "metadata": {
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    #4 feature inputs going into an 6-unit layer (more does not seem to help - in fact you can go down to 4)\n",
        "    model.add(Dense(6, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
        "    # \"Deep learning\" turns out to be unnecessary - this additional hidden layer doesn't help either.\n",
        "    model.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
        "    # Output layer with a binary classification (benign or malignant)\n",
        "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "    # Compile model; rmsprop seemed to work best\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Wrap our Keras model in an estimator compatible with scikit_learn\n",
        "estimator = KerasClassifier(build_fn=create_model, nb_epoch=100, verbose=0)\n",
        "# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n",
        "cv_scores = cross_val_score(estimator, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": [
              "0.5560671266508186"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-b666bf274d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do we have a winner?\n",
        "\nWhich model, and which choice of hyperparameters, performed the best? Feel free to share your results!"
      ],
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "clf = KMeans(n_clusters=2)\n",
        "cv_scores = cross_val_score(clf, all_features_scaled, all_classes, cv=10)\n",
        "cv_scores.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": [
              "-190.9602608001988"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn import neighbors\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "models = [\n",
        "    DecisionTreeClassifier(random_state=1),\n",
        "    RandomForestClassifier(n_estimators=10, random_state=1),\n",
        "    svm.SVC(kernel='linear', C=1.0),\n",
        "    svm.SVC(kernel='rbf', C=1.0),\n",
        "    svm.SVC(kernel='sigmoid', C=1.0),\n",
        "    svm.SVC(kernel='poly', C=1.0),\n",
        "    LogisticRegression(),\n",
        "    neighbors.KNeighborsClassifier(n_neighbors=10),\n",
        "    # MultinomialNB()\n",
        "]\n",
        "results = pd.DataFrame(columns=['score'])\n",
        "for model in models:\n",
        "    cv_scores = cross_val_score(model, all_features_scaled, all_classes, cv=10)\n",
        "    results.loc[model.__str__()] = cv_scores.mean()\n",
        "results.sort_values('score', ascending=False)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": [
              "                                                       score\n",
              "LogisticRegression(C=1.0, class_weight=None, du...  0.806374\n",
              "SVC(C=1.0, cache_size=200, class_weight=None, c...  0.800276\n",
              "SVC(C=1.0, cache_size=200, class_weight=None, c...  0.795543\n",
              "SVC(C=1.0, cache_size=200, class_weight=None, c...  0.790608\n",
              "KNeighborsClassifier(algorithm='auto', leaf_siz...  0.785715\n",
              "RandomForestClassifier(bootstrap=True, class_we...  0.744690\n",
              "SVC(C=1.0, cache_size=200, class_weight=None, c...  0.735385\n",
              "DecisionTreeClassifier(class_weight=None, crite...  0.732859"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0, warm_start=False)</th>\n",
              "      <td>0.806374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)</th>\n",
              "      <td>0.800276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)</th>\n",
              "      <td>0.795543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)</th>\n",
              "      <td>0.790608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\\n           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\\n           weights='uniform')</th>\n",
              "      <td>0.785715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\\n            oob_score=False, random_state=1, verbose=0, warm_start=False)</th>\n",
              "      <td>0.744690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)</th>\n",
              "      <td>0.735385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\\n            max_features=None, max_leaf_nodes=None,\\n            min_impurity_decrease=0.0, min_impurity_split=None,\\n            min_samples_leaf=1, min_samples_split=2,\\n            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\\n            splitter='best')</th>\n",
              "      <td>0.732859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 79,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "datascience",
      "language": "python",
      "display_name": "datascience"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "datascience"
    },
    "nteract": {
      "version": "0.5.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}